/*
 * ndp.c - NVMe Disk Performance benchmark tool
 *
 * A benchmark utility inspired by IRIX's diskperf. It measures I/O performance
 * using multiple threads and asynchronous I/O, supporting various test patterns.
 *
 * Compiles on both IRIX 6.5 (MIPSpro 7.4) and modern Linux.
 */

#ifndef __sgi
#define _GNU_SOURCE
#define _LARGEFILE64_SOURCE
#endif

#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <string.h>
#include <getopt.h>
#include <fcntl.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <sys/time.h>
#include <errno.h>
#include <pthread.h>
#include <aio.h>
#include <limits.h>
#include <signal.h>
#include <time.h>

/* Constants */
#define AIO_QUEUE_DEPTH 16

/* Test types - ordered to match diskperf output: fwd_wt, fwd_rd, bwd_wt, bwd_rd, rnd_wt, rnd_rd */
enum test_type {
    TEST_F_WRITE, TEST_F_READ,
    TEST_B_WRITE, TEST_B_READ,
    TEST_R_WRITE, TEST_R_READ,
    TEST_TYPE_COUNT
};

const char *test_names[] = {
    "fwd_wt", "fwd_rd", "bwd_wt", "bwd_rd", "rnd_wt", "rnd_rd"
};

struct options {
    int write_test;
    int direct_io;
    int async_io;
    int duration;
    long min_block_size;
    long max_block_size;
    off64_t test_file_size;
    int num_threads;
    char *test_path;
};

/* Per-thread worker context */
struct worker_context {
    int thread_id;
    int fd;
    enum test_type test_type;
    long block_size;
    off64_t region_offset;  /* Start offset for this thread's region */
    off64_t region_size;    /* Size of region this thread can access */
    int duration;
    int use_aio;            /* Use async I/O vs synchronous read/write */
    volatile int *stop_flag;
    pthread_mutex_t *stats_lock;
    unsigned long *total_bytes;
    unsigned long *total_ops;
};

/* AIO control block wrapper */
struct aio_context {
    struct aiocb cb;
    void *buffer;
    int in_use;
};

/* Random number generator state (thread-safe) */
static unsigned int rand_seed = 12345;

static unsigned int get_random(void) {
    /* Simple thread-safe(ish) LCG random */
    rand_seed = rand_seed * 1103515245 + 12345;
    return (rand_seed >> 16) & 0x7FFF;
}

// Function prototypes
void print_header(struct options *opts);
void run_benchmark(struct options *opts, int fd);
double run_single_test(struct options *opts, long block_size, enum test_type type, int fd);
void *worker_thread(void *arg);
double get_time_in_seconds(void);
int create_test_file(const char *path, off64_t size);

void usage(const char *progname) {
    fprintf(stderr, "Usage: %s [-W] [-D] [-a] [-t <time>] [-r <min>] [-m <max>] [-c <size>] [-j <threads>] <testpath>\n", progname);
    fprintf(stderr, "  -W: Enable write tests (default: read-only, non-destructive).\n");
    fprintf(stderr, "  -D: Use O_DIRECT (unbuffered I/O, bypasses kernel cache).\n");
    fprintf(stderr, "  -a: Use async I/O (aio_read/aio_write) instead of synchronous read/write/lseek.\n");
    fprintf(stderr, "  -t <time>: Duration in seconds for each test.\n");
    fprintf(stderr, "  -r <size>: Minimum block size (e.g., 4k).\n");
    fprintf(stderr, "  -m <size>: Maximum block size (e.g., 1m).\n");
    fprintf(stderr, "  -c <size>: Test file size (e.g., 1g).\n");
    fprintf(stderr, "  -j <threads>: Number of parallel threads.\n");
    fprintf(stderr, "  -h: Print this help message.\n");
    exit(1);
}

off64_t parse_size(char *str) {
    char *endptr;
    long long val = strtoll(str, &endptr, 10);
    if (*endptr == 'k' || *endptr == 'K') val *= 1024;
    else if (*endptr == 'm' || *endptr == 'M') val *= 1024 * 1024;
    else if (*endptr == 'g' || *endptr == 'G') val *= 1024LL * 1024 * 1024;
    return (off64_t)val;
}

double get_time_in_seconds(void) {
    struct timeval tv;
    gettimeofday(&tv, NULL);
    return (double)tv.tv_sec + (double)tv.tv_usec / 1000000.0;
}

void print_header(struct options *opts) {
    time_t now;
    char timestr[64];
    char hostname[256];

    /* Get current time */
    now = time(NULL);
    strftime(timestr, sizeof(timestr), "%a %b %d %H:%M:%S %Y", localtime(&now));

    /* Get hostname */
    if (gethostname(hostname, sizeof(hostname)) != 0) {
        strcpy(hostname, "unknown");
    }

    /* Print header matching diskperf format */
    printf("#---------------------------------------------------------\n");
    printf("# Disk Performance Test Results Generated By NDP V1.0\n");
    printf("#\n");
    printf("# Test name     : Unspecified\n");
    printf("# Test date     : %s\n", timestr);
    printf("# Test machine  : %s\n", hostname);
    printf("# Test type     : %s\n", opts->write_test ? "Read/Write" : "Read-only");
    printf("# Test path     : %s\n", opts->test_path);
    printf("# Request sizes : min=%ld max=%ld\n", opts->min_block_size, opts->max_block_size);
    printf("# Parameters    : direct=%d async=%d time=%d threads=%d\n",
           opts->direct_io, opts->async_io, opts->duration, opts->num_threads);
    printf("# File size     : %lld bytes\n", (long long)opts->test_file_size);
    printf("#---------------------------------------------------------\n");
    printf("# req_size  fwd_wt  fwd_rd  bwd_wt  bwd_rd  rnd_wt  rnd_rd\n");
    printf("#  (bytes)  (MB/s)  (MB/s)  (MB/s)  (MB/s)  (MB/s)  (MB/s)\n");
    printf("#---------------------------------------------------------\n");
}

void run_benchmark(struct options *opts, int fd) {
    long bs;
    int i;
    double result;

    for (bs = opts->min_block_size; bs > 0 && bs <= opts->max_block_size; bs *= 2) {
        printf("%11ld", bs);
        fflush(stdout);

        for (i = 0; i < TEST_TYPE_COUNT; i++) {
            result = 0.0;
            /* Skip write tests if -W is not specified */
            if ((i == TEST_F_WRITE || i == TEST_B_WRITE || i == TEST_R_WRITE) && !opts->write_test) {
                printf("    ---");
            } else {
                result = run_single_test(opts, bs, (enum test_type)i, fd);
                printf(" %7.2f", result);
            }
            fflush(stdout);
        }
        printf("\n");
    }
}

/* Worker thread that performs I/O operations */
void *worker_thread(void *arg) {
    struct worker_context *ctx;
    unsigned long local_bytes;
    unsigned long local_ops;
    off64_t offset;
    off64_t max_offset;
    int is_write;
    int is_random;
    int is_backward;
    void *buffer;
    int ret;
    ssize_t bytes_transferred;

    ctx = (struct worker_context *)arg;
    local_bytes = 0;
    local_ops = 0;

    /* Determine test pattern */
    is_write = (ctx->test_type == TEST_F_WRITE ||
                ctx->test_type == TEST_B_WRITE ||
                ctx->test_type == TEST_R_WRITE);
    is_random = (ctx->test_type == TEST_R_READ || ctx->test_type == TEST_R_WRITE);
    is_backward = (ctx->test_type == TEST_B_READ || ctx->test_type == TEST_B_WRITE);

    /* Allocate aligned buffer for I/O */
#ifdef __sgi
    buffer = memalign(4096, ctx->block_size);
#else
    if (posix_memalign(&buffer, 4096, ctx->block_size) != 0) {
        buffer = NULL;
    }
#endif
    if (!buffer) {
        fprintf(stderr, "Thread %d: Failed to allocate buffer\n", ctx->thread_id);
        return NULL;
    }

    /* Initialize buffer with pattern for writes */
    if (is_write) {
        memset(buffer, 0xAA ^ ctx->thread_id, ctx->block_size);
    }

    /* Calculate offset range within this thread's region */
    max_offset = ctx->region_offset + ctx->region_size - ctx->block_size;
    if (max_offset < ctx->region_offset) {
        max_offset = ctx->region_offset;
    }

    /* Initial offset based on pattern within this thread's region */
    if (is_backward) {
        offset = max_offset;
    } else {
        offset = ctx->region_offset;
    }

    /* Main I/O loop - use AIO or synchronous I/O based on config */
    if (ctx->use_aio) {
        /* Async I/O path - keep multiple requests in flight */
        struct aiocb aio_queue[AIO_QUEUE_DEPTH];
        void *buffers[AIO_QUEUE_DEPTH];
        const struct aiocb *aio_list[AIO_QUEUE_DEPTH];
        int in_flight;
        int i, slot;
        int err;

        /* Allocate buffers for all slots */
        for (i = 0; i < AIO_QUEUE_DEPTH; i++) {
#ifdef __sgi
            buffers[i] = memalign(4096, ctx->block_size);
#else
            if (posix_memalign(&buffers[i], 4096, ctx->block_size) != 0) {
                buffers[i] = NULL;
            }
#endif
            if (!buffers[i]) {
                fprintf(stderr, "Thread %d: Failed to allocate AIO buffer %d\n", ctx->thread_id, i);
                while (--i >= 0) {
                    free(buffers[i]);
                }
                free(buffer);
                return NULL;
            }
            if (is_write) {
                memset(buffers[i], 0xAA ^ ctx->thread_id, ctx->block_size);
            }
            memset(&aio_queue[i], 0, sizeof(struct aiocb));
        }

        in_flight = 0;

        /* Main loop: fill queue, suspend when full, harvest completions, repeat */
        while (!(*ctx->stop_flag)) {
            /* Fill queue up to capacity */
            while (in_flight < AIO_QUEUE_DEPTH && !(*ctx->stop_flag)) {
                /* Find a free slot */
                for (slot = 0; slot < AIO_QUEUE_DEPTH; slot++) {
                    if (aio_queue[slot].aio_fildes == 0) {
                        break;
                    }
                }

                /* No free slot found - this shouldn't happen but be safe */
                if (slot >= AIO_QUEUE_DEPTH) {
                    fprintf(stderr, "Thread %d: No free slots but in_flight=%d (should be %d)\n",
                            ctx->thread_id, in_flight, AIO_QUEUE_DEPTH);
                    break;
                }

                /* Submit new request - clear the aiocb first */
                memset(&aio_queue[slot], 0, sizeof(struct aiocb));
                aio_queue[slot].aio_fildes = ctx->fd;
                aio_queue[slot].aio_buf = buffers[slot];
                aio_queue[slot].aio_nbytes = ctx->block_size;
                aio_queue[slot].aio_offset = offset;

                if (is_write) {
                    ret = aio_write(&aio_queue[slot]);
                } else {
                    ret = aio_read(&aio_queue[slot]);
                }

                if (ret < 0) {
                    fprintf(stderr, "Thread %d: AIO submit failed: %s\n",
                            ctx->thread_id, strerror(errno));
                    break;
                }

                in_flight++;

                /* Calculate next offset */
                if (is_random) {
                    off64_t num_blocks = ctx->region_size / ctx->block_size;
                    if (num_blocks > 0) {
                        offset = ctx->region_offset + ((off64_t)get_random() % num_blocks) * ctx->block_size;
                    }
                } else if (is_backward) {
                    offset -= ctx->block_size;
                    if (offset < ctx->region_offset) {
                        offset = max_offset;
                    }
                } else {
                    offset += ctx->block_size;
                    if (offset > max_offset) {
                        offset = ctx->region_offset;
                    }
                }
            }

            /* Queue is full, rebuild list and wait for at least one completion */
            if (in_flight > 0) {
                /* Rebuild the list from scratch, only include requests still in progress */
                int list_count = 0;
                for (slot = 0; slot < AIO_QUEUE_DEPTH; slot++) {
                    if (aio_queue[slot].aio_fildes != 0) {
                        err = aio_error(&aio_queue[slot]);
                        if (err == EINPROGRESS) {
                            aio_list[list_count++] = &aio_queue[slot];
                        }
                    }
                }

                /* Only suspend if there are actually requests in progress */
                if (list_count > 0) {
                    struct timespec timeout;
                    timeout.tv_sec = ctx->duration;
                    timeout.tv_nsec = 0;

                    ret = aio_suspend(aio_list, list_count, &timeout);
                    if (ret < 0) {
                        if (errno == EAGAIN) {
                            fprintf(stderr, "Thread %d: WARNING: aio_suspend timed out after %d seconds\n",
                                    ctx->thread_id, ctx->duration);
                            fprintf(stderr, "  Submitted %d requests to aio_suspend:\n", list_count);

                            /* Dump what we passed to aio_suspend */
                            for (i = 0; i < list_count; i++) {
                                int queue_slot;
                                /* Find which slot this aiocb corresponds to */
                                for (queue_slot = 0; queue_slot < AIO_QUEUE_DEPTH; queue_slot++) {
                                    if (&aio_queue[queue_slot] == aio_list[i]) {
                                        break;
                                    }
                                }
                                err = aio_error(aio_list[i]);
                                fprintf(stderr, "  List[%d] -> Slot %d: fd=%d offset=%lld size=%ld status=%s\n",
                                        i, queue_slot,
                                        aio_list[i]->aio_fildes,
                                        (long long)aio_list[i]->aio_offset,
                                        (long)aio_list[i]->aio_nbytes,
                                        err == EINPROGRESS ? "INPROGRESS" :
                                        err == 0 ? "COMPLETE" : "ERROR");
                            }

                            /* Also dump the entire queue state for comparison */
                            fprintf(stderr, "  Full queue state:\n");
                            for (i = 0; i < AIO_QUEUE_DEPTH; i++) {
                                if (aio_queue[i].aio_fildes != 0) {
                                    err = aio_error(&aio_queue[i]);
                                    fprintf(stderr, "  Slot %d: fd=%d offset=%lld size=%ld status=%s\n",
                                            i, aio_queue[i].aio_fildes,
                                            (long long)aio_queue[i].aio_offset,
                                            (long)aio_queue[i].aio_nbytes,
                                            err == EINPROGRESS ? "INPROGRESS" :
                                            err == 0 ? "COMPLETE" : "ERROR");
                                }
                            }
                        } else if (errno != EINTR) {
                            fprintf(stderr, "Thread %d: aio_suspend failed: %s\n",
                                    ctx->thread_id, strerror(errno));
                        }
                    }
                }
            }

            /* Harvest completed requests */
            for (slot = 0; slot < AIO_QUEUE_DEPTH; slot++) {
                if (aio_queue[slot].aio_fildes == 0) {
                    continue;
                }

                err = aio_error(&aio_queue[slot]);
                if (err == EINPROGRESS) {
                    continue;
                }

                /* Request completed */
                ret = aio_return(&aio_queue[slot]);
                if (ret > 0) {
                    local_bytes += ret;
                    local_ops++;
                }

                /* Mark slot as free */
                aio_queue[slot].aio_fildes = 0;
                in_flight--;
            }
        }

        /* Wait for all in-flight operations to complete before freeing buffers */
        while (in_flight > 0) {
            for (slot = 0; slot < AIO_QUEUE_DEPTH; slot++) {
                if (aio_queue[slot].aio_fildes == 0) {
                    continue;
                }

                err = aio_error(&aio_queue[slot]);
                if (err == EINPROGRESS) {
                    continue;
                }

                /* Request completed */
                ret = aio_return(&aio_queue[slot]);
                if (ret > 0) {
                    local_bytes += ret;
                    local_ops++;
                }

                /* Mark slot as free */
                aio_queue[slot].aio_fildes = 0;
                in_flight--;
            }
        }

        /* Free AIO buffers */
        for (i = 0; i < AIO_QUEUE_DEPTH; i++) {
            free(buffers[i]);
        }
    } else {
        /* Synchronous I/O path (default, without -D) */
        while (!(*ctx->stop_flag)) {
            /* Seek to position */
            if (lseek64(ctx->fd, offset, SEEK_SET) < 0) {
                fprintf(stderr, "Thread %d: lseek64 failed at offset %lld: %s\n",
                        ctx->thread_id, (long long)offset, strerror(errno));
                break;
            }

            /* Perform synchronous I/O */
            if (is_write) {
                bytes_transferred = write(ctx->fd, buffer, ctx->block_size);
            } else {
                bytes_transferred = read(ctx->fd, buffer, ctx->block_size);
            }

            if (bytes_transferred < 0) {
                fprintf(stderr, "Thread %d: I/O error at offset %lld: %s\n",
                        ctx->thread_id, (long long)offset, strerror(errno));
                break;
            }

            /* Update statistics */
            local_bytes += bytes_transferred;
            local_ops++;

            /* Calculate next offset based on pattern within thread's region */
            if (is_random) {
                off64_t num_blocks = ctx->region_size / ctx->block_size;
                if (num_blocks > 0) {
                    offset = ctx->region_offset + ((off64_t)get_random() % num_blocks) * ctx->block_size;
                }
            } else if (is_backward) {
                offset -= ctx->block_size;
                if (offset < ctx->region_offset) {
                    offset = max_offset;
                }
            } else {
                /* Forward sequential */
                offset += ctx->block_size;
                if (offset > max_offset) {
                    offset = ctx->region_offset;
                }
            }
        }
    }

    /* Accumulate statistics (thread-safe) */
    pthread_mutex_lock(ctx->stats_lock);
    *ctx->total_bytes += local_bytes;
    *ctx->total_ops += local_ops;
    pthread_mutex_unlock(ctx->stats_lock);

    free(buffer);
    return NULL;
}

double run_single_test(struct options *opts, long block_size, enum test_type type, int fd) {
    pthread_t *threads;
    struct worker_context *contexts;
    pthread_mutex_t stats_lock;
    volatile int stop_flag;
    unsigned long total_bytes;
    unsigned long total_ops;
    double start_time, end_time, elapsed;
    double throughput_mbps;
    off64_t region_size;
    int i;

    stop_flag = 0;
    total_bytes = 0;
    total_ops = 0;

    /* Allocate thread contexts */
    threads = malloc(sizeof(pthread_t) * opts->num_threads);
    contexts = malloc(sizeof(struct worker_context) * opts->num_threads);
    if (!threads || !contexts) {
        fprintf(stderr, "Failed to allocate thread structures\n");
        free(threads);
        free(contexts);
        return 0.0;
    }

    /* Initialize mutex */
    pthread_mutex_init(&stats_lock, NULL);

    /* Calculate region size per thread */
    region_size = opts->test_file_size / opts->num_threads;

    /* Create worker threads */
    for (i = 0; i < opts->num_threads; i++) {
        contexts[i].thread_id = i;
        contexts[i].fd = fd;
        contexts[i].test_type = type;
        contexts[i].block_size = block_size;
        contexts[i].region_offset = i * region_size;
        contexts[i].region_size = region_size;
        contexts[i].duration = opts->duration;
        contexts[i].use_aio = opts->async_io;  /* Use AIO when -a flag is specified */
        contexts[i].stop_flag = &stop_flag;
        contexts[i].stats_lock = &stats_lock;
        contexts[i].total_bytes = &total_bytes;
        contexts[i].total_ops = &total_ops;

        if (pthread_create(&threads[i], NULL, worker_thread, &contexts[i]) != 0) {
            fprintf(stderr, "Failed to create thread %d\n", i);
            stop_flag = 1;
            break;
        }
    }

    /* Let test run for specified duration */
    start_time = get_time_in_seconds();
    sleep(opts->duration);
    stop_flag = 1;

    /* Wait for all threads to complete */
    for (i = 0; i < opts->num_threads; i++) {
        pthread_join(threads[i], NULL);
    }

    /* Measure actual elapsed time after all threads finish */
    end_time = get_time_in_seconds();
    elapsed = end_time - start_time;

    /* Calculate throughput in MB/s */
    throughput_mbps = (double)total_bytes / (1024.0 * 1024.0) / elapsed;

    /* Cleanup */
    pthread_mutex_destroy(&stats_lock);
    free(threads);
    free(contexts);

    return throughput_mbps;
}

/* Create and pre-fill a test file */
int create_test_file(const char *path, off64_t size) {
    int fd;
    char *fill_buf;
    off64_t remaining;
    size_t chunk_size = 4 * 1024 * 1024; /* 4MB chunks for faster creation */
    ssize_t written;
    size_t i;

    fd = open(path, O_CREAT | O_RDWR | O_TRUNC, 0644);
    if (fd < 0) {
        perror("Error creating test file");
        return -1;
    }

    /* Allocate and fill buffer with pseudo-random data */
    fill_buf = malloc(chunk_size);
    if (!fill_buf) {
        fprintf(stderr, "Error: Could not allocate buffer to create file\n");
        close(fd);
        return -1;
    }

    /* Fill buffer with pseudo-random pattern */
    for (i = 0; i < chunk_size / 4; i++) {
        ((unsigned int *)fill_buf)[i] = get_random() | (get_random() << 16);
    }

    remaining = size;
    while (remaining > 0) {
        size_t to_write = (size_t)((remaining > chunk_size) ? chunk_size : remaining);
        written = write(fd, fill_buf, to_write);
        if (written < 0) {
            fprintf(stderr, "Error writing file: %s\n", strerror(errno));
            free(fill_buf);
            close(fd);
            unlink(path);
            return -1;
        }
        remaining -= written;
    }

    /* Flush to disk to ensure all data is written */
    if (fsync(fd) != 0) {
        fprintf(stderr, "Warning: fsync failed: %s\n", strerror(errno));
    }

    free(fill_buf);
    close(fd);

    /* Brief sleep to let filesystem settle */
    sleep(5);

    return 0;
}

int main(int argc, char **argv) {
    int c;
    int flags;
    int fd;
    int created_file = 0;
    struct options opts;
#ifdef __sgi
    aioinit_t aioinit;
#endif

    /* Initialize options to zero */
    memset(&opts, 0, sizeof(opts));

    /* Default values */
    opts.min_block_size = 4096;
    opts.max_block_size = 1024 * 1024;
    opts.duration = 10;
    opts.num_threads = 1;
    opts.test_file_size = 0; /* No default - only create file if -c specified */

    while ((c = getopt(argc, argv, "WDat:r:m:c:j:h")) != -1) {
        switch (c) {
            case 'W':
                opts.write_test = 1;
                break;
            case 'D':
                opts.direct_io = 1;
                break;
            case 'a':
                opts.async_io = 1;
                break;
            case 't':
                opts.duration = atoi(optarg);
                break;
            case 'r':
                opts.min_block_size = (long)parse_size(optarg);
                break;
            case 'm':
                opts.max_block_size = (long)parse_size(optarg);
                break;
            case 'c':
                opts.test_file_size = parse_size(optarg);
                break;
            case 'j':
                opts.num_threads = atoi(optarg);
                break;
            case 'h':
            case '?':
                usage(argv[0]);
                break;
        }
    }

    if (optind < argc) {
        opts.test_path = argv[optind];
    } else {
        fprintf(stderr, "Error: test path is required.\n");
        usage(argv[0]);
    }

#ifdef __sgi
    /* Initialize IRIX AIO subsystem only if async I/O is requested */
    if (opts.async_io) {
        memset(&aioinit, 0, sizeof(aioinit));
        aioinit.aio_threads = opts.num_threads * 2 < 5 ? 5 : opts.num_threads * 2; /* Extra threads for AIO workers */
        aioinit.aio_locks = AIO_QUEUE_DEPTH < 3 ? 3 : AIO_QUEUE_DEPTH;
        aioinit.aio_numusers = opts.num_threads < 5 ? 5 : opts.num_threads;

        aio_sgi_init(&aioinit);
    }
#endif

    /* Print header before creating test file */
    print_header(&opts);

    /* Create test file if -c was specified */
    if (opts.test_file_size > 0) {
        if (create_test_file(opts.test_path, opts.test_file_size) != 0) {
            return 1;
        }
        created_file = 1;
    }

    /* Open the test file */
    if (opts.write_test) {
        flags = O_RDWR;
    } else {
        flags = O_RDONLY;
    }

    if (opts.direct_io) {
        flags |= O_DIRECT;
    }

    fd = open(opts.test_path, flags);
    if (fd < 0) {
        if (opts.direct_io && errno == EINVAL) {
            fprintf(stderr, "Warning: O_DIRECT not supported on this filesystem (%s)\n",
                    strerror(errno));
            fprintf(stderr, "         Continuing without O_DIRECT (buffered I/O)\n");
            /* Retry without O_DIRECT */
            flags = opts.write_test ? O_RDWR : O_RDONLY;
            fd = open(opts.test_path, flags);
            if (fd < 0) {
                perror("Error opening test path");
                if (created_file) unlink(opts.test_path);
                return 1;
            }
            opts.direct_io = 0;  /* Update flag to reflect actual state */
        } else {
            perror("Error opening test path");
            if (created_file) unlink(opts.test_path);
            return 1;
        }
    }

    /* If no -c was specified, get the actual file size */
    if (opts.test_file_size == 0) {
        struct stat st;
        if (fstat(fd, &st) == 0) {
            opts.test_file_size = st.st_size;
        } else {
            fprintf(stderr, "Error: Could not determine file size\n");
            close(fd);
            return 1;
        }
    }

    run_benchmark(&opts, fd);

    close(fd);

    /* Delete the test file if we created it */
    if (created_file) {
        if (unlink(opts.test_path) != 0) {
            perror("Warning: Could not delete test file");
        }
    }

    return 0;
}
